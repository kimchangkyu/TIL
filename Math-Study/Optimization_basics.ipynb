{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 최적화 기초"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 최적화 문제\n",
    "- 함수 $f(x)$의 값을 최대화 혹은 최소화하는 변수 $x$의 값 $x^{\\ast}$를 찾는 것\n",
    "\n",
    "    $ \n",
    "    x^{\\ast} = \\arg \\max_x f(x) \n",
    "    $\n",
    "    , \n",
    "    $ \n",
    "    x^{\\ast} = \\arg \\min_x f(x) \n",
    "    $\n",
    "\n",
    "- $x^{\\ast}$ : 최적화 문제의 해(solution)\n",
    "- 보통은 최소화 문제만 고려\n",
    "- 목적함수(objective function) : 최소화하려는 함수 $f(x)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 그리드 서치\n",
    "- 가능한 $x$의 값을 여러개 넣어 보고 그중 가장 작은 값을 선택\n",
    "- 가장 간단한 방법이지만 많은 $x$ 위치에 대해 목적함숫값을 계산해야 한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 수치적 최적화(numerical optimization)\n",
    "- 반복적 시행 착오에 의해 최적화 필요조건을 만족하는 값 $x^{\\ast}$를 찾는 방법\n",
    "- 함수 위치가 최적점이 될 때까지 가능한 한 적은 횟수만큼 $x$ 위치를 옮기는 방법\n",
    "\n",
    "- 다음 두 가지 알고리즘을 요구\n",
    "    * 현재 위치 $x_k$가 최적점인지 판단하는 알고리즘\n",
    "    * 어떤 위치 $x_k$를 시도한 뒤, 다음 번에 시도할 위치 $x_{k+1}$을 찾는 알고리즘\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 기울기 필요조건\n",
    "- 값 $x^{\\ast}$에서 함수의 기울기와 도함수 $\\dfrac{df}{dx}$ 값이 0이라는 조건을 만족하는 조건\n",
    "- 단일 변수에 대한 함수인 경우 : 미분값이 0\n",
    "\n",
    "    $\n",
    "    \\dfrac{df(x)}{dx} = 0\n",
    "    $\n",
    "    \n",
    "- 다변수 함수인 경우 : 모든 변수에 대한 편미분값이 0\n",
    "\n",
    "    $\n",
    "    \\dfrac{\\partial f(x_1, x_2, \\cdots , x_N)}{\\partial x_1} = 0 \\rightarrow\n",
    "    $\n",
    "    $ \n",
    "    \\nabla f = 0\\ (\\nabla f : gradient vector)\n",
    "    $\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 최대경사법\n",
    "- 단순히 현재 위치 $x_k$에서의 기울기 값 $g(x_k)$ 만을 이용하여 다음번 위치 $x_{k+1}$를 결정하는 방법\n",
    "\n",
    "    $ \n",
    "    x_{k+1} = x_{k} - \\mu \\nabla f(x_k) = x_{k} - \\mu g(x_k) \n",
    "    $\n",
    "\n",
    "- $\\mu$ : 스텝 사이즈(step size)\n",
    "    - 위치를 옮기는 거리를 결정하는 비례상수\n",
    "    \n",
    "- 스텝 사이즈의 크기를 적절히 조정하는 것이 중요\n",
    "    - 스텝 사이즈가 너무 작으면 최저점을 찾아가는데 시간이 너무 오래 걸린다.\n",
    "    - 스텝 사이즈가 너무 크면 오히려 최저점에서 멀어지는 현상이 발생\n",
    "\n",
    "- 곡면의 모양이 계곡(valley)과 같이 생긴 경우\n",
    "    - 그레디언트 벡터가 최저점을 가리키고 있지 않는 경우에는 진동이 발생\n",
    "    - -> 수렴하기까지 시간이 오래 걸릴 수 있다"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 진동 현상을 없앨 수 있는 방법\n",
    "- 2차 도함수, 즉 헤시안 행렬을 이용하는 방법\n",
    "- 모멘텀 방법(momentum) : 진행 방향으로 계속 진행하도록 성분(모멘텀)을 추가하는 것"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 준 뉴턴 방법\n",
    "- 현재 시도하고 있는 $x_n$ 주변의 몇몇 점에서 함수의 값을 구하고 이를 이용하여 2차 도함수의 근사값 혹은 이에 상응하는 정보를 수치적으로 계산\n",
    "- BFGS(Broyden–Fletcher–Goldfarb–Shanno) 방법이 많이 사용됨"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scipy를 이용한 최적화\n",
    "\n",
    "```\n",
    "import scipy as sp\n",
    "\n",
    "result = sp.optimize.minimize(func, x0, jac=jac)\n",
    "```\n",
    "\n",
    "* `func`: 목적함수\n",
    "* `x0`: 초깃값 벡터\n",
    "* `jac`: (옵션) 그레디언트 벡터를 출력하는 함수\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`minimize()` 명령의 결과\n",
    "\n",
    "* `x`: 최적화 해\n",
    "* `success`: 최적화에 성공하면 `True` 반환\n",
    "* `status`: 종료 상태. 최적화에 성공하면 0 반환\n",
    "* `message`: 메시지 문자열\n",
    "* `fun`: x 위치에서의 함수의 값\n",
    "* `jac`: x 위치에서의 자코비안(그레디언트) 벡터의 값 \n",
    "* `hess_inv`: x 위치에서의 헤시안 행렬의 역행렬의 값 \n",
    "* `nfev`: 목적함수 호출 횟수\n",
    "* `njev`: 자코비안 계산 횟수\n",
    "* `nhev`: 헤시안 계산 횟수\n",
    "* `nit`: x 이동 횟수"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 전역 최적화 문제\n",
    "- 만약 최적화하려는 함수가 복수의 국소 최저점(local minima)을 가지고 있는 경우\n",
    "    - 수치적 최적화 방법으로 전역 최저점(global minimum)에 도달한다는 보장이 없다. \n",
    "    - 결과는 초기 추정값 및 알고리즘, 파라미터 등에 의존한다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 컨벡스 문제\n",
    "- 목적함수의 2차 도함수의 값이 항상 0 이상이 되는 영역에서만 정의된 최적화 문제\n",
    "\n",
    "    $ \n",
    "    \\dfrac{\\partial^2 f}{\\partial x^2} \\geq 0 \n",
    "    $\n",
    "\n",
    "- 다변수 목적함수의 경우\n",
    "    - 주어진 영역에서 헤시안 행렬이 항상 양의 준정부호(positive semidefinite)이라는 조건이 된다.\n",
    "\n",
    "        $ \n",
    "        x^THx \\geq 0 \\;\\;\\text{for all } x \n",
    "        $\n",
    "- 컨벡스 문제에서는 항상 전역 최저점이 존재한다. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
